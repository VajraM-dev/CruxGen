{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"CruxGen","text":"<p>Create LLM-ready datasets. Straight from the source.</p>"},{"location":"#what-is-cruxgen","title":"What is CruxGen?","text":"<p>CruxGen automates the creation of synthetic question-answer datasets from your company's unstructured documents. Upload PDFs and DOCX files, and let AI generate contextually relevant Q&amp;A pairs ready for LLM training.</p> <p>Problem: Creating training datasets manually is time-intensive and expensive. Solution: Automated pipeline that processes documents and generates structured Q&amp;A pairs.</p>"},{"location":"#key-features","title":"Key Features","text":"<ul> <li>Document Processing: Upload and manage PDF/DOCX files</li> <li>Intelligent Chunking: Automatically split documents into meaningful segments</li> <li>QA Generation: Generate contextual question-answer pairs using LLM</li> <li>Export Ready: Download datasets in JSONL format for training</li> <li>Enterprise Ready: Vault integration, PostgreSQL storage, MinIO object storage</li> </ul>"},{"location":"#quick-start","title":"Quick Start","text":""},{"location":"#1-install-the-sdk","title":"1. Install the SDK","text":"<pre><code>pip install cruxgen-sdk\n</code></pre>"},{"location":"#2-process-your-first-document","title":"2. Process Your First Document","text":"<pre><code>from cruxgen_sdk import CruxGenSDK\n\nwith CruxGenSDK(\"http://localhost:8000\") as sdk:\n    # Upload document\n    result = sdk.upload_file(\"company-policy.pdf\")\n    file_id = result[\"response\"]\n\n    # Create chunks\n    sdk.create_chunks(file_id, \"default-bucket\")\n\n    # Generate QA pairs\n    sdk.create_qa_pairs(file_id)\n\n    # Export dataset\n    qa_data = sdk.get_qa_pairs(file_id, generate_jsonl=True)\n    with open(\"training_data.jsonl\", \"wb\") as f:\n        f.write(qa_data)\n</code></pre>"},{"location":"#3-use-your-dataset","title":"3. Use Your Dataset","text":"<p>The generated JSONL file contains structured Q&amp;A pairs ready for LLM training:</p> <pre><code>{\"question\": \"What is the company's remote work policy?\", \"answer\": \"Employees may work remotely up to 3 days per week...\"}\n{\"question\": \"How do I submit vacation requests?\", \"answer\": \"Vacation requests must be submitted through the HR portal...\"}\n</code></pre>"},{"location":"#architecture","title":"Architecture","text":"<p>CruxGen follows a modular pipeline architecture:</p> <ol> <li>Document Storage \u2192 MinIO object storage</li> <li>Document Chunking \u2192 Docling text splitters</li> <li>QA Generation \u2192 OpenAI API processing</li> <li>Data Management \u2192 PostgreSQL with SQLAlchemy</li> <li>API Layer \u2192 FastAPI with automatic documentation</li> </ol>"},{"location":"#api-components","title":"API Components","text":""},{"location":"#core-services","title":"Core Services","text":"<ul> <li>Main Application - FastAPI server with health checks</li> <li>Document Management - File upload, storage, and metadata</li> <li>Chunk Management - Document splitting and chunk operations</li> <li>QA Management - Question-answer pair generation</li> </ul>"},{"location":"#client-sdk","title":"Client SDK","text":"<ul> <li>Python SDK - Complete SDK for CruxGen API</li> </ul>"},{"location":"#dependencies","title":"Dependencies","text":"<p>Core Stack:</p> <ul> <li>FastAPI 0.116.1+ (API framework)</li> <li>SQLAlchemy 2.0.43+ (database ORM)</li> <li>MinIO 7.2.16+ (object storage)</li> <li>PostgreSQL (primary database)</li> </ul> <p>LLM Processing:</p> <ul> <li>Litellm (llm management)</li> </ul> <p>Infrastructure:</p> <ul> <li>HashiCorp Vault (secrets management)</li> <li>Tenacity 9.1.2+ (retry logic)</li> <li>Python 3.11+ required</li> </ul>"},{"location":"#getting-started","title":"Getting Started","text":""},{"location":"#prerequisites","title":"Prerequisites","text":"<ol> <li>Database: PostgreSQL instance</li> <li>Object Storage: MinIO server</li> <li>Secrets: HashiCorp Vault</li> <li>LLM API: OpenAI API key</li> </ol>"},{"location":"#installation","title":"Installation","text":"<pre><code># Clone repository\ngit clone https://github.com/your-org/cruxgen\ncd cruxgen\n\n# Install dependencies\npip install -e .\n\n# Configure environment\ncp .env.example .env\n# Edit .env with your credentials\n\n# Start server\npython main.py\n</code></pre>"},{"location":"#health-check","title":"Health Check","text":"<p>Verify all systems are operational:</p> <pre><code>curl http://localhost:8000/health\n</code></pre>"},{"location":"#workflow","title":"Workflow","text":""},{"location":"#document-to-dataset-pipeline","title":"Document to Dataset Pipeline","text":"<ol> <li>Upload documents (PDF/DOCX) to MinIO storage</li> <li>Process files into database-tracked chunks</li> <li>Generate Q&amp;A pairs using LLM processing</li> <li>Export structured datasets for training</li> </ol>"},{"location":"#typical-usage-pattern","title":"Typical Usage Pattern","text":"<pre><code># 1. Document Management\nsdk.create_bucket(\"documents\")\nresult = sdk.upload_file(\"manual.pdf\", \"documents\")\nfile_id = result[\"response\"]\n\n# 2. Content Processing\nsdk.create_chunks(file_id, \"documents\")\nchunks = sdk.get_chunks(file_id)\n\n# 3. Dataset Generation\nsdk.create_qa_pairs(file_id)\ndataset = sdk.get_qa_pairs(file_id, generate_jsonl=True)\n\n# 4. Export and Use\nwith open(\"training_set.jsonl\", \"wb\") as f:\n    f.write(dataset)\n</code></pre>"},{"location":"future_work/","title":"Future Work","text":"<ul> <li>Deployment ready docker and docker compose</li> <li>Adding async support in sdk</li> <li>Handling batch processing</li> <li>Implementing Celery and RabbitMQ for advanced processing</li> <li>Support for more document formats with added support for images and tables</li> </ul>"},{"location":"sdk/","title":"CruxGen SDK","text":"<p>Python SDK for CruxGen API - Create LLM-ready datasets from documents.</p>"},{"location":"sdk/#installation","title":"Installation","text":"<pre><code>pip install cruxgen-sdk\n</code></pre>"},{"location":"sdk/#requirements","title":"Requirements","text":"<ul> <li>Python 3.13+</li> <li>httpx 0.28.1+</li> <li>orjson 3.11.3+</li> </ul>"},{"location":"sdk/#quick-start","title":"Quick Start","text":"<pre><code>from cruxgen_sdk import CruxGenSDK\n\n# Initialize SDK\nwith CruxGenSDK(\"http://localhost:8000\") as sdk:\n    # Health check\n    health = sdk.health_check()\n    print(health)\n</code></pre>"},{"location":"sdk/#initialization","title":"Initialization","text":"<pre><code>sdk = CruxGenSDK(\n    base_url=\"http://localhost:8000\",  # API base URL\n    timeout=300.0                      # Request timeout in seconds\n)\n</code></pre>"},{"location":"sdk/#document-management","title":"Document Management","text":""},{"location":"sdk/#create-bucket","title":"Create Bucket","text":"<pre><code>result = sdk.create_bucket(\"my-bucket\")\n</code></pre>"},{"location":"sdk/#upload-file","title":"Upload File","text":"<pre><code>result = sdk.upload_file(\"path/to/file.pdf\", bucket_name=\"my-bucket\")\nfile_id = result[\"response\"]  # Extract file ID for further operations\n</code></pre>"},{"location":"sdk/#delete-object","title":"Delete Object","text":"<pre><code>result = sdk.delete_object(\"my-bucket\", \"file.pdf\")\n</code></pre>"},{"location":"sdk/#delete-bucket","title":"Delete Bucket","text":"<pre><code>result = sdk.delete_bucket(\"my-bucket\")\n</code></pre>"},{"location":"sdk/#list-objects","title":"List Objects","text":"<pre><code># List all objects\nobjects = sdk.list_objects()\n\n# List objects in specific bucket\nobjects = sdk.list_objects(\"my-bucket\")\n\n# List with prefix filter\nobjects = sdk.list_objects(\"my-bucket\", prefix=\"docs/\", recursive=True)\n</code></pre>"},{"location":"sdk/#list-buckets","title":"List Buckets","text":"<pre><code>buckets = sdk.list_buckets()\n</code></pre>"},{"location":"sdk/#get-object-info","title":"Get Object Info","text":"<pre><code>info = sdk.get_object_info(\"my-bucket\", \"file.pdf\")\n</code></pre>"},{"location":"sdk/#get-file-id-by-name","title":"Get File ID by Name","text":"<pre><code>file_info = sdk.get_file_id_by_name(\"file.pdf\")\nfile_id = file_info[\"response\"]\n</code></pre>"},{"location":"sdk/#chunk-management","title":"Chunk Management","text":""},{"location":"sdk/#create-chunks","title":"Create Chunks","text":"<pre><code>result = sdk.create_chunks(file_id, \"my-bucket\")\n</code></pre>"},{"location":"sdk/#get-chunks","title":"Get Chunks","text":"<pre><code>chunks = sdk.get_chunks(file_id)\nchunk_texts = chunks[\"response\"]  # List of chunk texts\n</code></pre>"},{"location":"sdk/#delete-chunks","title":"Delete Chunks","text":"<pre><code>result = sdk.delete_chunks(file_id)\n</code></pre>"},{"location":"sdk/#qa-management","title":"QA Management","text":""},{"location":"sdk/#create-qa-pairs","title":"Create QA Pairs","text":"<pre><code># Process all chunks\nresult = sdk.create_qa_pairs(file_id)\n\n# Process specific chunk\nresult = sdk.create_qa_pairs(file_id, chunk_id=\"chunk-123\")\n</code></pre>"},{"location":"sdk/#get-qa-pairs","title":"Get QA Pairs","text":"<pre><code># Get as JSON\nqa_pairs = sdk.get_qa_pairs(file_id)\n\n# Download as JSONL file\nqa_jsonl = sdk.get_qa_pairs(file_id, generate_jsonl=True)\nif isinstance(qa_jsonl, bytes):\n    with open(f\"qa_pairs_{file_id}.jsonl\", \"wb\") as f:\n        f.write(qa_jsonl)\n</code></pre>"},{"location":"sdk/#delete-qa-pairs","title":"Delete QA Pairs","text":"<pre><code>result = sdk.delete_qa_pairs(file_id)\n</code></pre>"},{"location":"sdk/#health-check","title":"Health Check","text":"<pre><code>health = sdk.health_check()\nstatus = health[\"status\"]  # \"ok\" or \"error\"\n</code></pre>"},{"location":"sdk/#complete-workflow-example","title":"Complete Workflow Example","text":"<pre><code>from cruxgen_sdk import CruxGenSDK\n\ndef process_document(file_path: str):\n    with CruxGenSDK(\"http://localhost:8000\") as sdk:\n        # 1. Create bucket\n        sdk.create_bucket(\"documents\")\n\n        # 2. Upload document\n        upload_result = sdk.upload_file(file_path, \"documents\")\n        file_id = upload_result[\"response\"]\n\n        # 3. Create chunks\n        sdk.create_chunks(file_id, \"documents\")\n\n        # 4. Generate QA pairs\n        sdk.create_qa_pairs(file_id)\n\n        # 5. Export QA dataset\n        qa_jsonl = sdk.get_qa_pairs(file_id, generate_jsonl=True)\n        with open(f\"dataset_{file_id}.jsonl\", \"wb\") as f:\n            f.write(qa_jsonl)\n\n        return file_id\n</code></pre>"},{"location":"sdk/#context-manager-usage","title":"Context Manager Usage","text":"<p>The SDK supports context manager protocol for automatic resource cleanup:</p> <pre><code># Recommended approach\nwith CruxGenSDK(\"http://localhost:8000\") as sdk:\n    result = sdk.health_check()\n\n# Manual cleanup\nsdk = CruxGenSDK(\"http://localhost:8000\")\ntry:\n    result = sdk.health_check()\nfinally:\n    sdk.close()\n</code></pre>"},{"location":"sdk/#error-handling","title":"Error Handling","text":"<p>The SDK raises <code>httpx.HTTPStatusError</code> for HTTP errors:</p> <pre><code>import httpx\n\ntry:\n    result = sdk.upload_file(\"nonexistent.pdf\")\nexcept httpx.HTTPStatusError as e:\n    print(f\"HTTP Error: {e.response.status_code}\")\nexcept FileNotFoundError:\n    print(\"File not found\")\n</code></pre>"},{"location":"sdk/#response-format","title":"Response Format","text":"<p>All methods return dictionaries with standardized structure:</p> <pre><code>{\n    \"success\": true,\n    \"message\": \"Operation completed successfully\",\n    \"status_code\": 200,\n    \"response\": {/* operation-specific data */}\n}\n</code></pre>"},{"location":"api_routers/chunk_management/","title":"Chunk Management API","text":"<p>Document chunking and chunk management endpoints.</p>"},{"location":"api_routers/chunk_management/#endpoints","title":"Endpoints","text":""},{"location":"api_routers/chunk_management/#create-chunks","title":"Create Chunks","text":"<p><pre><code>POST /chunks/create-chunks\n</code></pre> Creates chunks from a document stored in MinIO.</p> <p>Request Body: <pre><code>{\n  \"file_id\": \"string\",\n  \"bucket_name\": \"string\"\n}\n</code></pre></p> <p>Response: <code>APIOutputResponse</code> with chunk creation results</p> <p>Notes: - Uses <code>DocumentSplitter</code> with default <code>ChunkerConfig</code> - Loads document from MinIO and splits into chunks - Stores chunks in database</p>"},{"location":"api_routers/chunk_management/#delete-chunks","title":"Delete Chunks","text":"<p><pre><code>DELETE /chunks/delete-chunks\n</code></pre> Deletes all chunks associated with a file ID.</p> <p>Request Body: <pre><code>{\n  \"file_id\": \"string\"\n}\n</code></pre></p> <p>Response: <code>APIOutputResponse</code> with deletion count</p>"},{"location":"api_routers/chunk_management/#get-chunks","title":"Get Chunks","text":"<p><pre><code>GET /chunks/get-chunks\n</code></pre> Retrieves all chunks for a specific file.</p> <p>Query Parameters: - <code>file_id</code>: string (required)</p> <p>Response: <code>APIOutputResponse</code> with array of chunk texts</p>"},{"location":"api_routers/chunk_management/#error-handling","title":"Error Handling","text":"<p>All endpoints return standardized error responses: - <code>400</code>: Bad Request - <code>500</code>: Internal Server Error</p>"},{"location":"api_routers/chunk_management/#dependencies","title":"Dependencies","text":"<ul> <li><code>DocumentSplitter</code> for chunk creation</li> <li>Database for chunk storage and retrieval</li> <li>MinIO for document access</li> </ul>"},{"location":"api_routers/document_router/","title":"Document Management API","text":"<p>MinIO-based document storage and management endpoints.</p>"},{"location":"api_routers/document_router/#endpoints","title":"Endpoints","text":""},{"location":"api_routers/document_router/#create-bucket","title":"Create Bucket","text":"<p><pre><code>POST /document/create-bucket\n</code></pre> Creates a new MinIO bucket.</p> <p>Request Body: <pre><code>{\n  \"bucket_name\": \"string\"\n}\n</code></pre></p> <p>Response: <code>APIOutputResponse</code></p>"},{"location":"api_routers/document_router/#upload-file","title":"Upload File","text":"<p><pre><code>POST /document/upload-file\n</code></pre> Uploads a file to MinIO bucket and registers it in the database.</p> <p>Parameters: - <code>file</code>: UploadFile (multipart/form-data) - <code>bucket_name</code>: string (default: \"default-bucket\")</p> <p>Response: <code>APIOutputResponse</code> with <code>file_id</code> in response field</p> <p>Notes: - Checks for existing files in database - Creates database record - Uses temporary file storage during upload</p>"},{"location":"api_routers/document_router/#delete-object","title":"Delete Object","text":"<p><pre><code>DELETE /document/delete-object\n</code></pre> Deletes object from MinIO and removes all associated database records.</p> <p>Request Body: <pre><code>{\n  \"bucket_name\": \"string\",\n  \"object_name\": \"string\"\n}\n</code></pre></p> <p>Response: <code>APIOutputResponse</code></p> <p>Notes: - Removes QA pairs, chunks, and file records from database - Deletes object from MinIO storage</p>"},{"location":"api_routers/document_router/#delete-bucket","title":"Delete Bucket","text":"<p><pre><code>DELETE /document/delete-bucket\n</code></pre> Deletes a MinIO bucket.</p> <p>Request Body: <pre><code>{\n  \"bucket_name\": \"string\"\n}\n</code></pre></p> <p>Response: <code>APIOutputResponse</code></p>"},{"location":"api_routers/document_router/#list-objects","title":"List Objects","text":"<p><pre><code>GET /document/list-objects\n</code></pre> Lists objects in a MinIO bucket.</p> <p>Query Parameters: - <code>bucket_name</code>: string (optional) - <code>prefix</code>: string (optional) - <code>recursive</code>: boolean (default: false)</p> <p>Response: <code>APIOutputResponse</code> with object list</p>"},{"location":"api_routers/document_router/#list-buckets","title":"List Buckets","text":"<p><pre><code>POST /document/list-buckets\n</code></pre> Lists all MinIO buckets.</p> <p>Response: <code>APIOutputResponse</code> with bucket list</p>"},{"location":"api_routers/document_router/#get-object-info","title":"Get Object Info","text":"<p><pre><code>GET /document/get-object-info\n</code></pre> Retrieves metadata for a specific object.</p> <p>Query Parameters: - <code>bucket_name</code>: string (required) - <code>object_name</code>: string (required)</p> <p>Response: <code>APIOutputResponse</code> with object metadata</p>"},{"location":"api_routers/document_router/#get-file-id","title":"Get File ID","text":"<p><pre><code>GET /document/get_file_id_from_name\n</code></pre> Retrieves file ID from database using filename.</p> <p>Query Parameters: - <code>file_name</code>: string (required)</p> <p>Response: <code>APIOutputResponse</code> with <code>file_id</code></p>"},{"location":"api_routers/document_router/#error-handling","title":"Error Handling","text":"<p>All endpoints return standardized error responses: - <code>400</code>: Bad Request - <code>404</code>: Not Found - <code>500</code>: Internal Server Error</p>"},{"location":"api_routers/document_router/#dependencies","title":"Dependencies","text":"<ul> <li>MinIO for object storage</li> <li>Database for file metadata</li> <li>Temporary file handling for uploads</li> </ul>"},{"location":"api_routers/main/","title":"CruxGen API","text":"<p>Create LLM-ready datasets. Straight from the source.</p>"},{"location":"api_routers/main/#overview","title":"Overview","text":"<p>FastAPI application for document processing, chunking, and QA pair generation for LLM training datasets.</p>"},{"location":"api_routers/main/#base-url","title":"Base URL","text":"<pre><code>http://localhost:8000\n</code></pre>"},{"location":"api_routers/main/#core-endpoints","title":"Core Endpoints","text":""},{"location":"api_routers/main/#root","title":"Root","text":"<p><pre><code>GET /\n</code></pre> Returns basic API greeting.</p> <p>Response: <pre><code>{\n  \"Hello\": \"World\"\n}\n</code></pre></p>"},{"location":"api_routers/main/#health-check","title":"Health Check","text":"<p><pre><code>GET /health\n</code></pre> Comprehensive system health status.</p> <p>Response: - <code>200</code>: All systems operational - <code>500</code>: System failure</p> <p>Checks: - Vault connection - Database connection - MinIO connection</p> <p>Response Format: <pre><code>{\n  \"status\": \"ok|error\",\n  \"message\": \"error details (if any)\"\n}\n</code></pre></p>"},{"location":"api_routers/main/#api-routes","title":"API Routes","text":""},{"location":"api_routers/main/#document-management","title":"Document Management","text":"<p><pre><code>/document/*\n</code></pre> MinIO-based file storage and management. - Upload/delete files - Bucket operations - Object metadata</p>"},{"location":"api_routers/main/#chunk-management","title":"Chunk Management","text":"<p><pre><code>/chunks/*\n</code></pre> Document chunking operations. - Create chunks from documents - Delete/retrieve chunks - Chunk configuration</p>"},{"location":"api_routers/main/#qa-management","title":"QA Management","text":"<p><pre><code>/qa/*\n</code></pre> Question-Answer pair generation. - Process chunks to QA pairs - Export QA datasets - QA pair management</p>"},{"location":"api_routers/main/#dependencies","title":"Dependencies","text":"<p>Core Stack: - FastAPI 0.116.1+ - SQLAlchemy 2.0.43+ - MinIO 7.2.16+ - Uvicorn 0.35.0+</p> <p>LLM Processing: - OpenAI 1.102.0+ - LangChain Docling 1.0.0+ - LangChain Text Splitters 0.3.9+</p> <p>Infrastructure: - PostgreSQL (psycopg2 2.9.10+) - HashiCorp Vault (hvac 2.3.0+) - Tenacity 9.1.2+ (retry logic)</p> <p>Utilities: - Python Multipart 0.0.20+ - Python DotEnv 1.1.1+ - PyFuncMonitor 0.1.2+</p>"},{"location":"api_routers/main/#configuration","title":"Configuration","text":"<p>Python: 3.11+</p> <p>Environment Variables: - Database connection details - Vault configuration - MinIO credentials - OpenAI API keys</p>"},{"location":"api_routers/main/#running","title":"Running","text":"<pre><code>python main.py\n</code></pre> <p>Server Details: - Host: 0.0.0.0 - Port: 8000 - Auto-reload: Enabled in development</p>"},{"location":"api_routers/qa_management/","title":"QA Management API","text":"<p>Question-Answer pair generation and management endpoints.</p>"},{"location":"api_routers/qa_management/#endpoints","title":"Endpoints","text":""},{"location":"api_routers/qa_management/#process-chunks-to-qa","title":"Process Chunks to QA","text":"<p><pre><code>POST /qa/process-chunks-to-qa\n</code></pre> Generates QA pairs from document chunks.</p> <p>Request Body: <pre><code>{\n  \"file_id\": \"string\",\n  \"chunk_id\": \"string (optional)\"\n}\n</code></pre></p> <p>Response: <code>APIOutputResponse</code> with QA generation results</p> <p>Notes: - Processes all chunks for the file if <code>chunk_id</code> not provided - Generates QA pairs using LLM processing - Stores QA pairs in database</p>"},{"location":"api_routers/qa_management/#delete-qa-pairs","title":"Delete QA Pairs","text":"<p><pre><code>DELETE /qa/delete-qa-pairs\n</code></pre> Deletes all QA pairs associated with a file.</p> <p>Request Body: <pre><code>{\n  \"file_id\": \"string\"\n}\n</code></pre></p> <p>Response: <code>APIOutputResponse</code> with deletion results</p>"},{"location":"api_routers/qa_management/#get-qa-pairs","title":"Get QA Pairs","text":"<p><pre><code>GET /qa/get-qa-pairs/{file_id}\n</code></pre> Retrieves all QA pairs for a specific file.</p> <p>Path Parameters: - <code>file_id</code>: string (required)</p> <p>Query Parameters: - <code>generate_jsonl</code>: boolean (default: false)</p> <p>Response:  - If <code>generate_jsonl=false</code>: <code>APIOutputResponse</code> with QA pairs array - If <code>generate_jsonl=true</code>: JSONL file download (<code>application/jsonl</code>)</p> <p>Notes: - JSONL download includes filename: <code>qa_pairs_{file_id}.jsonl</code> - Each line in JSONL contains a single QA pair object</p>"},{"location":"api_routers/qa_management/#error-handling","title":"Error Handling","text":"<p>All endpoints return standardized error responses: - <code>400</code>: Bad Request - <code>500</code>: Internal Server Error</p>"},{"location":"api_routers/qa_management/#dependencies","title":"Dependencies","text":"<ul> <li>LLM processing pipeline for QA generation</li> <li>Database for QA pair storage and retrieval</li> <li>Chunk data for QA generation</li> </ul>"}]}